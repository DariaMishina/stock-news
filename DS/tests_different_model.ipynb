{"nbformat":4,"nbformat_minor":4,"metadata":{"notebookId":"a33fca66-087f-4204-b121-1a7ce5d28caa","language_info":{"version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split","metadata":{"cellId":"wx40o0upnk55it6745bsm","trusted":true},"outputs":[],"execution_count":79},{"cell_type":"code","source":"dataset = pd.read_csv('out.csv',index_col=0)  \ndataset = dataset.dropna()","metadata":{"cellId":"evd9r8a18pu7r1j72nzi","trusted":true},"outputs":[],"execution_count":80},{"cell_type":"code","source":"dataset['binary_lables']=dataset['binary_lables'].shift(periods=-1) # Смещаю метки на день вперед ","metadata":{"cellId":"prdqip4y32amxirqoreen","trusted":true},"outputs":[],"execution_count":81},{"cell_type":"code","source":"dataset = dataset.dropna()","metadata":{"cellId":"ihsen2xpgq8fopkphed8i","trusted":true},"outputs":[],"execution_count":82},{"cell_type":"code","source":"dataset.head(10)","metadata":{"cellId":"0env8qsu8g89y4p31ep9gis","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"                 Open       High        Low      Close  Adj Close      Volume  \\\n2017-01-03  38.630001  39.080002  38.340000  39.049999  36.148453   9677300.0   \n2017-01-04  39.060001  39.730000  39.060001  39.360001  36.435421  22644500.0   \n2017-01-05  39.240002  39.750000  38.980000  39.700001  36.750153  12080100.0   \n2017-01-06  39.700001  40.990002  39.660000  40.779999  37.749912  14628900.0   \n2017-01-09  40.790001  41.060001  40.619999  40.740002  37.712887  10992500.0   \n2017-01-10  40.810001  41.619999  40.779999  41.290001  38.222012   9256300.0   \n2017-01-11  41.049999  41.419998  40.490002  41.080002  38.273254  10699400.0   \n2017-01-12  40.790001  40.790001  40.310001  40.720001  37.937847   8633400.0   \n2017-01-13  40.750000  41.360001  40.689999  40.930000  38.133503   9533300.0   \n2017-01-17  40.669998  41.040001  40.529999  40.900002  38.105549   8272700.0   \n\n            per_of_growth  Mid_tone  Sum_count  binary_lables  \n2017-01-03       1.087233 -0.180050        106            1.0  \n2017-01-04       0.768047 -0.840975        122            1.0  \n2017-01-05       1.172271 -0.881550        119            1.0  \n2017-01-06       2.720398 -0.618025        151            0.0  \n2017-01-09      -0.122577 -1.428850        253            1.0  \n2017-01-10       1.176181 -1.289425        219            1.0  \n2017-01-11       0.073088 -0.778575        202            0.0  \n2017-01-12      -0.171610 -1.006225        253            1.0  \n2017-01-13       0.441719 -0.331825        123            1.0  \n2017-01-17       0.565536 -0.137375        120            0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n      <th>per_of_growth</th>\n      <th>Mid_tone</th>\n      <th>Sum_count</th>\n      <th>binary_lables</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-03</th>\n      <td>38.630001</td>\n      <td>39.080002</td>\n      <td>38.340000</td>\n      <td>39.049999</td>\n      <td>36.148453</td>\n      <td>9677300.0</td>\n      <td>1.087233</td>\n      <td>-0.180050</td>\n      <td>106</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-04</th>\n      <td>39.060001</td>\n      <td>39.730000</td>\n      <td>39.060001</td>\n      <td>39.360001</td>\n      <td>36.435421</td>\n      <td>22644500.0</td>\n      <td>0.768047</td>\n      <td>-0.840975</td>\n      <td>122</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-05</th>\n      <td>39.240002</td>\n      <td>39.750000</td>\n      <td>38.980000</td>\n      <td>39.700001</td>\n      <td>36.750153</td>\n      <td>12080100.0</td>\n      <td>1.172271</td>\n      <td>-0.881550</td>\n      <td>119</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-06</th>\n      <td>39.700001</td>\n      <td>40.990002</td>\n      <td>39.660000</td>\n      <td>40.779999</td>\n      <td>37.749912</td>\n      <td>14628900.0</td>\n      <td>2.720398</td>\n      <td>-0.618025</td>\n      <td>151</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-09</th>\n      <td>40.790001</td>\n      <td>41.060001</td>\n      <td>40.619999</td>\n      <td>40.740002</td>\n      <td>37.712887</td>\n      <td>10992500.0</td>\n      <td>-0.122577</td>\n      <td>-1.428850</td>\n      <td>253</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-10</th>\n      <td>40.810001</td>\n      <td>41.619999</td>\n      <td>40.779999</td>\n      <td>41.290001</td>\n      <td>38.222012</td>\n      <td>9256300.0</td>\n      <td>1.176181</td>\n      <td>-1.289425</td>\n      <td>219</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-11</th>\n      <td>41.049999</td>\n      <td>41.419998</td>\n      <td>40.490002</td>\n      <td>41.080002</td>\n      <td>38.273254</td>\n      <td>10699400.0</td>\n      <td>0.073088</td>\n      <td>-0.778575</td>\n      <td>202</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-12</th>\n      <td>40.790001</td>\n      <td>40.790001</td>\n      <td>40.310001</td>\n      <td>40.720001</td>\n      <td>37.937847</td>\n      <td>8633400.0</td>\n      <td>-0.171610</td>\n      <td>-1.006225</td>\n      <td>253</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-13</th>\n      <td>40.750000</td>\n      <td>41.360001</td>\n      <td>40.689999</td>\n      <td>40.930000</td>\n      <td>38.133503</td>\n      <td>9533300.0</td>\n      <td>0.441719</td>\n      <td>-0.331825</td>\n      <td>123</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-17</th>\n      <td>40.669998</td>\n      <td>41.040001</td>\n      <td>40.529999</td>\n      <td>40.900002</td>\n      <td>38.105549</td>\n      <td>8272700.0</td>\n      <td>0.565536</td>\n      <td>-0.137375</td>\n      <td>120</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"X_row = dataset[[\"per_of_growth\",\"Mid_tone\",'Sum_count']]\nY_row = dataset[[\"binary_lables\"]]","metadata":{"cellId":"z7i0k5spksa3xsxa8hpfdv","trusted":true},"outputs":[],"execution_count":85},{"cell_type":"code","source":"scaler = StandardScaler().fit(X_row)\nx = scaler.transform(X_row)","metadata":{"cellId":"5di776la1vh0qtsf0n6nfzd","trusted":true},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# enc = OneHotEncoder()\n# enc.fit(Y_row)\n# y =enc.transform(Y_row)","metadata":{"cellId":"wfkql4uy5n17ezo4pf5t9","trusted":true},"outputs":[],"execution_count":87},{"cell_type":"code","source":"le = LabelEncoder()\ny = le.fit_transform(Y_row)\nle.classes_\n","metadata":{"cellId":"fy2fmpzz5hu2yxj0lll7g","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"},{"output_type":"display_data","data":{"text/plain":"array([0., 1.])"},"metadata":{}}],"execution_count":90},{"cell_type":"code","source":"len(x) ==len(y)","metadata":{"cellId":"duvy31sgwbe8zew1gnirm","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"True"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"#Делю на тестовый и тренеровочный\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,shuffle = False) # 70% training and 30% test","metadata":{"cellId":"wbmlpd1gsmpfncqgj4kvzu","trusted":true},"outputs":[],"execution_count":116},{"cell_type":"code","source":"from sklearn import svm\nfrom sklearn import metrics\n","metadata":{"cellId":"cwmw0d7x46btqbvc4scsf","trusted":true},"outputs":[],"execution_count":97},{"cell_type":"code","source":"clf = svm.SVC(random_state =42) # Linear Kernel\n#Train the model using the training sets\nclf.fit(X_train, y_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"cellId":"xc88eh3j5ogw8t0po5oksq","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.5122743533862412\n"}],"execution_count":111},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nclf = MLPClassifier(random_state =42,hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"cellId":"v1htwcdpyincla23fxyteo","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.5136724371890291\n"}],"execution_count":112},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization","metadata":{"cellId":"6tuoin18him9lpmhm709","trusted":true},"outputs":[],"execution_count":126},{"cell_type":"code","source":"\nmod=Sequential()\nmod.add(LSTM(units = 64, return_sequences = True, input_shape = (3,9)))\nmod.add(Dropout(0.2))\nmod.add(BatchNormalization())\nmod.add(LSTM(units = 64, return_sequences = True))\nmod.add(Dropout(0.1))\nmod.add(BatchNormalization())\n\nmod.add((LSTM(units = 64)))\nmod.add(Dropout(0.1))\nmod.add(BatchNormalization())\nmod.add((Dense(units = 16, activation='tanh')))\nmod.add(BatchNormalization())\nmod.add((Dense(units = 1, activation='sigmoid')))\n\nmod.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"cellId":"skbtry0gx8rpwtsm0npvb","trusted":true},"outputs":[],"execution_count":127},{"cell_type":"code","source":"model.fit(X_train, y_train, epochs=5, batch_size=2048)","metadata":{"cellId":"jqghud5eagnqs32xak72","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5168\nEpoch 2/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5169\nEpoch 3/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6926 - accuracy: 0.5167\nEpoch 4/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5167\nEpoch 5/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5168\n"},{"output_type":"display_data","data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fed40eb5910>"},"metadata":{}}],"execution_count":131},{"cell_type":"code","source":"mod=Sequential()\nmod.add(layers.Dense(3, activation='relu'))\nmod.add(layers.Dense(32, activation='relu'))\nmod.add(Dropout(0.1))\nmod.add(BatchNormalization())\nmod.add((LSTM(units = 64)))\nmod.add(Dropout(0.1))\nmod.add(BatchNormalization())\nmod.add((Dense(units = 16, activation='tanh')))\nmod.add(BatchNormalization())\nmod.add((Dense(units = 1, activation='sigmoid')))\n\nmod.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"cellId":"fgw8gn7v0fjbkzf9hnod1m","trusted":true},"outputs":[],"execution_count":136},{"cell_type":"code","source":"model.fit(X_train, y_train, epochs=5, batch_size=2048)","metadata":{"cellId":"jecqepqrj10cpy00rn3djd","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5166\nEpoch 2/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5165\nEpoch 3/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5167\nEpoch 4/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5167\nEpoch 5/5\n56743/56743 [==============================] - 0s 1us/step - loss: 0.6925 - accuracy: 0.5167\n"},{"output_type":"display_data","data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fed40e6c950>"},"metadata":{}}],"execution_count":137},{"cell_type":"code","source":"","metadata":{"cellId":"qnajedqoasxqv6qpgsrj"},"outputs":[],"execution_count":null}]}